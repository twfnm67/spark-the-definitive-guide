{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bd7ba06-e8d6-44e3-83fb-0997c9793ea6",
   "metadata": {},
   "source": [
    "- 구조적 API는 비정형 로그 파일부터 반정형 CSV 파일, 매우 정형적인 파케이 파일까지 다양한 유형의 데이터를 처리할 수 있음\n",
    "- 구조적 API에는 다음과 같은 세 가지 분산 컬렉션 API가 있음\n",
    "    - Dataset\n",
    "    - DataFrame\n",
    "    - SQL 테이블 뷰\n",
    "- 배치와 스트리밍 처리에서 구조적 API 이용(배치 작업을 손쉽게 스트리밍 작업으로 변환할 수 있고 반대도 가능)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ce137-cf71-4e67-bbc3-616481b6fd54",
   "metadata": {},
   "source": [
    "- 이 장에서 반드시 이해할 것\n",
    "    - 타입형(typed) / 비타입형(untyped) API 개념과 차이점\n",
    "    - 핵심 용어\n",
    "    - 스파크가 구조적 API의 데이터 흐름을 해석하고 클러스터에서 실행하는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c0e0b0-c516-43f8-83b7-bceab301582d",
   "metadata": {},
   "source": [
    "# 4.1 DataFrame과 Dataset\n",
    "- DataFrame, Dataset : 잘 정의된 '로우'와 '컬럼'을 가지는 분산 테이블 형태의 컬렉션"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aa89c9-ec58-45cd-9bd7-fa19bfbf7b4c",
   "metadata": {},
   "source": [
    "# 4.2 스키마"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efe7d43-65e2-4a70-a4ff-5336b791cf6e",
   "metadata": {},
   "source": [
    "# 4.3 스파크의 구조적 데이터 타입 개요\n",
    "- 카탈리스트 엔진 : 자체 데이터 타입 정보를 가지고 있으며 다양한 실행 최적화 기능 제공\n",
    "- 스파크가 지원하는 언어를 이용해 작성된 표현식을 카탈리스트 엔진에서 스파크의 데이터 타입으로 변환해 명령을 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5541f53a-1ae1-46e6-8640-88c36b6fc0dc",
   "metadata": {},
   "source": [
    "## 4.3.1 DataFrame과 Dataset 비교\n",
    "- '비타입형' DataFrame : 스키마에 명시된 데이터 타입의 일치 여부를 런타임이 되어서야 확인. Row 타입으로 구성된 Dataset\n",
    "- '타입형' Dataset : 스키마에 명시된 데이터 타입의 일치 여부를 컴파일 타임에 확인 (스칼라(case class)와 자바(JavaBean)에서만 지원)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd116bb0-5e34-4b19-b49b-6145b6128b12",
   "metadata": {},
   "source": [
    "## 4.3.2 컬럼\n",
    "- 단순 데이터 타입\n",
    "- 복합 데이터 타입 e.g. 배열\n",
    "- null 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3c40e8-b655-4293-a26d-11398f50c88f",
   "metadata": {},
   "source": [
    "# 4.4 구조적 API의 실행 과정\n",
    "1. DataFrame/Dataset/SQL을 이용해 코드 작성\n",
    "2. 스파크가 논리적 실행 계획으로 변환\n",
    "3. 스파크는 논리적 실행 계획을 물리적 실행 계획으로 변환. 추가 최적화 여부 확인\n",
    "4. 물리적 실행 계획(RDD 처리)을 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e1e78d-4815-423e-9f05-aad4219502c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
