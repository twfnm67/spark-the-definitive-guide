{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2af87bf2-6763-454e-a39f-ba3ff210ea23",
   "metadata": {},
   "source": [
    "- DataFrame을 다루는 기능\n",
    "    - Row 타입의 레코드와 각 레코드에 수행할 연산 표현식을 나타내는 여러 컬럼으로 구성\n",
    "    - 스키마\n",
    "    - 파티셔닝\n",
    "    - 파티셔닝 스키마 : 파티션을 배치하는 방법을 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60477a1-78b9-4ac0-baf5-de8e9355f31f",
   "metadata": {},
   "source": [
    "- DataFrame 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df901681-ace8-43a9-ac9b-6aeecec1752c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.0.2:4040\n",
       "SparkContext available as 'sc' (version = 3.3.2, master = local[*], app id = local-1681772094003)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "res0: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@5450c6e8\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f7c76c-d6fb-4aa5-8fb6-72eca6f08996",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.format(\"json\").load(\"sample_data/flight-data/json/2015-summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6092d6d3-0d53-40ea-9bf4-f1c0e0d3e9f3",
   "metadata": {},
   "source": [
    "- 스키마 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b860c960-e2a3-490b-98ee-005420c571f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b63f02-2cce-402d-a524-303e441b041a",
   "metadata": {},
   "source": [
    "# 5.1 스키마"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14eeaf11-ad84-4ab0-b7ba-0b0708978c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res2: org.apache.spark.sql.types.StructType = StructType(StructField(DEST_COUNTRY_NAME,StringType,true),StructField(ORIGIN_COUNTRY_NAME,StringType,true),StructField(count,LongType,true))\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.format(\"json\").load(\"sample_data/flight-data/json/2015-summary.json\").schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec68c59-c833-4e98-b5ba-90a187a6bf1c",
   "metadata": {},
   "source": [
    "- 스키마는 여러 개의 StructField 타입으로 구성된 StructType 객체\n",
    "- StructField는 이름, 데이터 타입, 컬럼이 값이 없거나 null일 수 있는지 지정하는 불리언 값을 가짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a64e371-806e-4c70-a586-9ad9dadc1125",
   "metadata": {},
   "source": [
    "- DataFrame에 스키마를 만들고 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03f34c43-2216-4997-8dd5-85d3e425d90e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.{StructField, StructType, StringType, LongType}\n",
       "import org.apache.spark.sql.types.Metadata\n",
       "myManualSchema: org.apache.spark.sql.types.StructType = StructType(StructField(DEST_COUNTRY_NAME,StringType,true),StructField(ORIGIN_COUNTRY_NAME,StringType,true),StructField(count,LongType,false))\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructField, StructType, StringType, LongType}\n",
    "import org.apache.spark.sql.types.Metadata\n",
    "\n",
    "val myManualSchema = StructType(Array(\n",
    "    StructField(\"DEST_COUNTRY_NAME\", StringType, true),\n",
    "    StructField(\"ORIGIN_COUNTRY_NAME\", StringType, true),\n",
    "    StructField(\"count\", LongType, false,\n",
    "                Metadata.fromJson(\"{\\\"hello\\\":\\\"world\\\"}\"))\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf69e0-38bd-4a76-8e61-973b7432f24d",
   "metadata": {},
   "source": [
    "## 5.2 컬럼과 표현식\n",
    "- 표현식으로 DataFrame의 컬럼을 선택, 조작, 제거할 수 있음\n",
    "- DataFrame을 통하지 않으면 외부에서 컬럼에 접근할 수 없음\n",
    "- 컬럼 내용을 수정하려면 반드시 DataFrame의 스파크 트랜스포메이션을 사용해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802e6c92-fb32-4b6a-9834-1ee58ab884f3",
   "metadata": {},
   "source": [
    "## 5.2.1 컬럼\n",
    "- col, column함수를 이용해 컬럼을 생성 및 참조\n",
    "- 컬럼명을 인수로 받음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cf3f994-e53c-4e12-badd-0cd2a16b074b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.{col, column}\n",
       "res3: org.apache.spark.sql.Column = someColumnName\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.{col, column}\n",
    "\n",
    "col(\"someColumnName\")\n",
    "column(\"someColumnName\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c6c4e4-fd38-4fbe-b5c0-825663f4f90e",
   "metadata": {},
   "source": [
    "- 컬럼은 컬럼명을 카탈로그에 저장된 정보와 비교하기 전까지는 미확인 상태로 남음\n",
    "- 컬럼이 DataFrame에 있을지 없을지는 알 수 없음\n",
    "- 분석기가 동작하는 단계에서 컬럼과 테이블을 분석함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c3dec3-8823-47bc-9e8f-ebb753efd61f",
   "metadata": {},
   "source": [
    "### 명시적 컬럼 참조\n",
    "- col 메서드로 참조\n",
    "- 조인 시 유용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "900d0b3b-484c-46a2-a68a-90ec548cf29e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res4: org.apache.spark.sql.Column = count\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.col(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a3fd03-45a1-499e-8984-c772f90873aa",
   "metadata": {},
   "source": [
    "## 5.2.2 표현식\n",
    "- DataFrame 레코드의 여러 값에 대한 트랜스포메이션 집합\n",
    "- 여러 컬럼을 입력으로 받아 식별하고, '단일 값'을 만들기 위해 다양한 표현식을 각 레코드에 적용하는 함수\n",
    "- expr 함수로 가장 간단히 사용 가능\n",
    "- 예) expr(\"someCol\")은 col(\"someCol\") 구문과 동일하게 동작"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd8682b-f52c-4592-b0c9-ccc37688671a",
   "metadata": {},
   "source": [
    "### 표현식으로 컬럼 표현\n",
    "- 컬럼은 단지 표현식일 뿐\n",
    "- 컬럼과 컬럼의 트랜스포메이션은 파싱된 표현식과 동일한 논리적 실행 계획으로 컴파일됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59b92ac-366b-47dc-98d8-dccd3501b902",
   "metadata": {},
   "source": [
    "(((col(\"someCol\")+5)*200)-6) < col(\"otherCol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a9f3b91-8925-4067-b04c-0a44e5634363",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.expr\n",
       "res5: org.apache.spark.sql.Column = ((((someCol + 5) * 200) - 6) < otherCol)\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.expr\n",
    "\n",
    "expr(\"(((someCol + 5) * 200) - 6) < otherCol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369cd757-d0fa-482a-bcb4-a191761df6d1",
   "metadata": {},
   "source": [
    "# 5.3 레코드와 로우\n",
    "- 값을 생성하기 위한 컬럼 표현식으로 Row 객체를 다룸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "868a3d26-70af-4580-a5be-0bac322b28da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res7: org.apache.spark.sql.Row = [United States,Romania,15]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// DataFrame의 first 메서드로 로우 확인\n",
    "df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbc5c92-6706-4ba9-a44e-7115115791a7",
   "metadata": {},
   "source": [
    "## 5.3.1 로우 생성하기\n",
    "- Row 객체는 스키마 정보를 가지고 있지 않음(DataFrame만 스키마를 가짐)\n",
    "- DataFrame의 스키마와 같은 순서로 값을 명시해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62f13550-e736-4af1-a219-519273c078bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.Row\n",
       "myRow: org.apache.spark.sql.Row = [Hello,null,1,false]\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.Row\n",
    "\n",
    "val myRow = Row(\"Hello\", null, 1, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "653c668d-18a7-437f-b6c5-a6623b6a9d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res8: Any = Hello\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//로우의 데이터에 접근\n",
    "myRow(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b0364-fd9b-4f8e-9d6e-263c7f972909",
   "metadata": {},
   "source": [
    "# 5.4 DataFrame의 트랜스포메이션\n",
    "- 로우나 컬럼 추가\n",
    "- 로우나 컬럼 제거\n",
    "- 로우를 컬럼으로 변환하거나, 그 반대로 변환\n",
    "- 컬럼값을 기준으로 로우 순서 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a00dc9-da0a-4a8f-8222-044c36ad9930",
   "metadata": {},
   "source": [
    "## 5.4.1 DataFrame 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63ae02c6-b287-465d-8a65-70e61eccaa4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//DataFrame을 생성\n",
    "val df = spark.read.format(\"json\").load(\"sample_data/flight-data/json/2015-summary.json\")\n",
    "\n",
    "//생성한 DataFrame을 SQL 쿼리를 실행하고 SQL의 기본 트랜스포메이션을 확인하기 위해 임시 뷰로 등록\n",
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20980878-be01-4590-bb3e-366b4109a2d9",
   "metadata": {},
   "source": [
    "## 5.4.2 select와 selectExpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8124a4f-435a-4d12-a781-1ae361995443",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"DEST_COUNTRY_NAME\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3382f76c-d1cb-4d8c-b37a-590042f28c34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "|newColumnName|DEST_COUNTRY_NAME|\n",
      "+-------------+-----------------+\n",
      "|United States|    United States|\n",
      "|United States|    United States|\n",
      "+-------------+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//selectExpr 메서드\n",
    "df.selectExpr(\"DEST_COUNTRY_NAME as newColumnName\", \"DEST_COUNTRY_NAME\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f71652-397c-47cf-bae3-c1685af377e5",
   "metadata": {},
   "source": [
    "- selectExpr 메서드는 새로운 DataFrame을 생성하는 복잡한 표현식을 간단하게 만드는 도구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f32226d7-0274-449e-8dea-a59a5f32c061",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//column 추가 예제\n",
    "df.selectExpr(\n",
    "    \"*\", //모든 원본 컬럼 포함\n",
    "    \"(DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME) as withinCountry\")\n",
    ".show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf0b4d7-95c7-4215-9172-d0f2baa9df6b",
   "metadata": {},
   "source": [
    "## 5.4.3 스파크 데이터 타입으로 변환하기\n",
    "- 새로운 값이 아닌 명시적인 값을 스파크에 전달해야 할 때\n",
    "- 추후에 비교에 사용할 무언가가 될 수 있음\n",
    "- 리터럴 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16c2f9d7-e27b-477e-a897-cfd2c72725e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|One|\n",
      "+-----------------+-------------------+-----+---+\n",
      "|    United States|            Romania|   15|  1|\n",
      "|    United States|            Croatia|    1|  1|\n",
      "+-----------------+-------------------+-----+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions.lit\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions.lit\n",
    "\n",
    "df.select(expr(\"*\"), lit(1).as(\"One\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48d235f-0c26-40f7-9bce-6f9c1487fb21",
   "metadata": {},
   "source": [
    "## 5.4.4 컬럼 추가하기\n",
    "- withColumn 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43c5b754-2abb-4640-bbab-c57845ff7947",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|numberOne|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "|    United States|            Romania|   15|        2|\n",
      "|    United States|            Croatia|    1|        2|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"numberOne\", lit(2)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38675906-ae43-41ed-8ffa-7147c4705a24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//출발지와 도착지가 같은지를 불리언 타입으로 표현\n",
    "df.withColumn(\"withinCountry\", expr(\"ORIGIN_COUNTRY_NAME == DEST_COUNTRY_NAME\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005d7fdc-fa0e-4199-8244-a34ad33a9231",
   "metadata": {},
   "source": [
    "## 5.4.5 컬럼명 변경하기\n",
    "- withColumnRenamed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2004cfa9-f811-48a4-a0ba-f7842732790f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res20: Array[String] = Array(dest, ORIGIN_COUNTRY_NAME, count)\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumnRenamed(\"DEST_COUNTRY_NAME\", \"dest\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e50b5f-8bb2-4bc7-a6f1-cdcc1398ff83",
   "metadata": {},
   "source": [
    "## 5.4.8 컬럼 제거하기\n",
    "- drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38a28c2b-815d-4c1c-bbe6-df733c3b1de9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|DEST_COUNTRY_NAME|count|\n",
      "+-----------------+-----+\n",
      "|    United States|   15|\n",
      "|    United States|    1|\n",
      "+-----------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.drop(\"ORIGIN_COUNTRY_NAME\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "316ab2b1-a503-4328-8fd0-a217f789f9b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac34c299-1e8e-44e7-99a5-f0f4702fcb59",
   "metadata": {},
   "source": [
    "## 5.4.9 컬럼의 데이터 타입 변경하기\n",
    "- cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "adb54273-f9a0-41bc-82d0-9a0a6dc750f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res25: org.apache.spark.sql.DataFrame = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn(\"count2\", col(\"count\").cast(\"string\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e55ddf9-8968-4a0f-b112-5e66e1e53c60",
   "metadata": {},
   "source": [
    "## 5.4.10 로우 필터링하기\n",
    "- filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eafa1825-e4ae-40b6-b4e4-a8b7b21415b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"count\") < 2).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b839a31d-11c3-4cf3-8d63-b7c9b44759de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(\"count < 2\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4f00a2-dcf7-439c-a6bf-0cbd3071eb48",
   "metadata": {},
   "source": [
    "## 5.4.11 고유한 로우 얻기\n",
    "- distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7a4ea36-b7d7-48e5-a7dd-5deaf085ffb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res28: Long = 256\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"ORIGIN_COUNTRY_NAME\", \"DEST_COUNTRY_NAME\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0529f2c4-7c1e-446e-8521-b4818547c5ca",
   "metadata": {},
   "source": [
    "## 5.4.12 무작위 샘플 만들기\n",
    "- sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6d33421-c20a-4ca7-8eb0-9123bafe8f5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seed: Int = 5\n",
       "withReplacement: Boolean = false\n",
       "fraction: Double = 0.5\n",
       "res30: Long = 138\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val seed = 5\n",
    "val withReplacement = false //복원추출 여부\n",
    "val fraction = 0.5 //표본 데이터 추출 비율\n",
    "df.sample(withReplacement, fraction, seed).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa72934d-20f0-401a-b53b-22f6f524db00",
   "metadata": {},
   "source": [
    "## 5.4.13 임의 분할하기\n",
    "- 머신러닝 알고리즘에서 사용할 학습셋, 검증셋 그리고 테스트셋을 만들 때 주로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "515a4c0d-4cf5-46d6-81c8-ede8a49245a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataFrames: Array[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]] = Array([DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field], [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field])\n",
       "res31: Boolean = false\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataFrames = df.randomSplit(Array(0.25, 0.75), seed)\n",
    "dataFrames(0).count() > dataFrames(1).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622eb0c2-99ac-428c-8020-4306afe34fc6",
   "metadata": {},
   "source": [
    "## 5.4.14 로우 합치기와 추가하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4451cd64-8d02-4d93-9572-7244880eea81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|          Singapore|    1|\n",
      "|    United States|          Gibraltar|    1|\n",
      "|    United States|             Cyprus|    1|\n",
      "|    United States|            Estonia|    1|\n",
      "|    United States|          Lithuania|    1|\n",
      "|    United States|           Bulgaria|    1|\n",
      "|    United States|            Georgia|    1|\n",
      "|    United States|            Bahrain|    1|\n",
      "|    United States|   Papua New Guinea|    1|\n",
      "|    United States|         Montenegro|    1|\n",
      "|    United States|            Namibia|    1|\n",
      "|    New Country 2|    Other Country 2|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.Row\n",
       "schema: org.apache.spark.sql.types.StructType = StructType(StructField(DEST_COUNTRY_NAME,StringType,true),StructField(ORIGIN_COUNTRY_NAME,StringType,true),StructField(count,LongType,true))\n",
       "newRows: Seq[org.apache.spark.sql.Row] = List([New Country,Other Country,5], [New Country 2,Other Country 2,1])\n",
       "parallelizedRows: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] = ParallelCollectionRDD[108] at parallelize at <console>:39\n",
       "newDF: org.apache.spark.sql.DataFrame = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.Row\n",
    "\n",
    "val schema = df.schema\n",
    "\n",
    "val newRows = Seq(\n",
    "    Row(\"New Country\", \"Other Country\", 5L),\n",
    "    Row(\"New Country 2\", \"Other Country 2\", 1L)\n",
    "    )\n",
    "\n",
    "val parallelizedRows = spark.sparkContext.parallelize(newRows)\n",
    "\n",
    "val newDF = spark.createDataFrame(parallelizedRows, schema)\n",
    "\n",
    "df.union(newDF).where(\"count = 1\").where($\"ORIGIN_COUNTRY_NAME\" =!= \"United States\")\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f026d0-596d-4210-a71a-a6407144b1c0",
   "metadata": {},
   "source": [
    "## 5.4.15 로우 정렬하기\n",
    "- sort, orderBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db507100-c05f-49fb-87f0-917dc6ea8ba9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|               Malta|      United States|    1|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|          Gibraltar|    1|\n",
      "|       United States|          Singapore|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|     Burkina Faso|      United States|    1|\n",
      "|    Cote d'Ivoire|      United States|    1|\n",
      "|           Cyprus|      United States|    1|\n",
      "|         Djibouti|      United States|    1|\n",
      "|        Indonesia|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|     Burkina Faso|      United States|    1|\n",
      "|    Cote d'Ivoire|      United States|    1|\n",
      "|           Cyprus|      United States|    1|\n",
      "|         Djibouti|      United States|    1|\n",
      "|        Indonesia|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(\"count\").show(5)\n",
    "df.orderBy(\"count\", \"DEST_COUNTRY_NAME\").show(5)\n",
    "df.orderBy(col(\"count\"), col(\"DEST_COUNTRY_NAME\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb4ec0b-cd1b-4154-9f29-f8ed59ebead5",
   "metadata": {},
   "source": [
    "## 5.4.16 로우 수 제한하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c5058eb-7cb8-450e-936a-8b998dc51b44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc34690b-a738-42e6-a475-f834730b3dd6",
   "metadata": {},
   "source": [
    "## 5.4.17 repartition과 coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4ed1273-f203-4605-9e39-aa880973ab28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res36: Int = 1\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c357da8c-5ca1-4c0e-abaf-a8f248b034fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res37: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.repartition(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b7fbd85-9da5-4453-8326-82cbc02220a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res39: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.repartition(col(\"DEST_COUNTRY_NAME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4881d8ce-d5d6-4fa6-9635-edcdc117559c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res40: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//목적지를 기준으로 셔플을 수행해 5개의 파티션으로 나누고, 전체 데이터를 셔플 없이 병합하는 예제\n",
    "df.repartition(5, col(\"DEST_COUNTRY_NAME\")).coalesce(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9d0e48-dff4-4c52-a4b0-10d6eb83af49",
   "metadata": {},
   "source": [
    "## 5.4.18 드라이버로 로우 데이터 수집하기\n",
    " - Executor 에 할당된 RDD 를 모두 Driver Node 로 취합하는 Action "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7c02d479-9fe5-45be-8788-66010a2bb786",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "|    United States|          Singapore|    1|\n",
      "|    United States|            Grenada|   62|\n",
      "|       Costa Rica|      United States|  588|\n",
      "|          Senegal|      United States|   40|\n",
      "|          Moldova|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |15   |\n",
      "|United States    |Croatia            |1    |\n",
      "|United States    |Ireland            |344  |\n",
      "|Egypt            |United States      |15   |\n",
      "|United States    |India              |62   |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "collectDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n",
       "res41: Array[org.apache.spark.sql.Row] = Array([United States,Romania,15], [United States,Croatia,1], [United States,Ireland,344], [Egypt,United States,15], [United States,India,62], [United States,Singapore,1], [United States,Grenada,62], [Costa Rica,United States,588], [Senegal,United States,40], [Moldova,United States,1])\n"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val collectDF = df.limit(10)\n",
    "collectDF.take(5)\n",
    "collectDF.show()\n",
    "collectDF.show(5, false)\n",
    "collectDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40dafa6-c65e-45cc-ae24-9c66d8149327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
