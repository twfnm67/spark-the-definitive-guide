{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d94c632-71d0-4e34-ab1a-514e75bb1ab5",
   "metadata": {},
   "source": [
    "# 10.1 SQL이란\n",
    "- 스파크는 ANSI SQL:2003의 일부를 구현하였음\n",
    "    - ANSI SQL:2003은 대부분의 SQL 데이터베이스에서 채택하고 있는 표준\n",
    "- 그러므로 스파크는 유명한 벤치마크인 TPC-DS를 성공적으로 통과할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3538eda-d034-44bd-85f3-b6e4199abb9a",
   "metadata": {},
   "source": [
    "# 10.2 빅데이터와 SQL: 아파치 하이브\n",
    "- 스파크 등장 전에는 하이브가 빅데이터 SQL 접근 계층에서 사실상의 표준이었음\n",
    "    - 페이스북에서 최초로 개발\n",
    "    - SQL 처리가 필요한 빅데이터 업계에서 믿을 수 없을 정도로 인기 있는 도구가 되었음\n",
    "- 이제는 많은 사용자가 스파크 SQL을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c66862-89d2-4868-bf16-eada9fa4f895",
   "metadata": {},
   "source": [
    "# 10.3 빅데이터와 SQL: 스파크 SQL\n",
    "- 스파크 2.0 버전에는 하이브를 지원할 수 있는 상위 호환 기능으로 ANSI-SQL과 HiveQL을 모두 지원한느 자체 개발된 SQL 파서가 포함되어 있음\n",
    "- 스파크 SQL은 DataFrame과의 뛰어난 호환성 덕분에 다양한 기업에서 강력한 기능으로 자리매김"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21088f4-78b7-47e7-bfb1-e7c318dad90a",
   "metadata": {},
   "source": [
    "## 10.3.1 스파크와 하이브의 관계\n",
    "- 스파크 SQL은 하이브 메타스토어를 사용하므로 하이브와 잘 연동할 수 있음\n",
    "    - 하이브 메타스토어는 여러 세션에서 사용할 테이블 정보를 보관하고 있음\n",
    "    - 스파크 SQL은 하이브 메타스토어에 접속(이미 하이브를 사용하고 있는 경우)한 뒤 조회할 파일 수를 최소화하기 위해 메타데이터를 참조\n",
    "    - 이 기능은 기존 하둡 환경의 모든 워크로드를 스파크로 이관하려는 사용자들에게 인기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8de249d-c182-4f39-ba99-05bca7566f20",
   "metadata": {},
   "source": [
    "### 하이브 메타스토어\n",
    "- 하이브 메타스토어에 접속하기 위한 몇 가지 속성\n",
    "    - 접근하려는 하이브 메타스토어에 적합한 버전을 spark.sql.hive.metastore.version에 설정\n",
    "    - HiveMetastoreClient가 초기화되는 방식을 변경하려면 spark.sql.hive.metastore.jars를 설정\n",
    "    - 하이브 메타스토어가 저장된 다른 데이터베이스에 접속하려면 적합한 클래스 접두사(MySQL 사용하려면 com.mysql.jdbc로 명시)를 정의해야 함\n",
    "    - 스파크와 하이브에서 공유할 수 있도록 클래스 접두사를 spark.sql.hive.metastore.sharedPrefixes 속성에 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b68520-2fbf-4b35-9f23-7b1eec9277ff",
   "metadata": {},
   "source": [
    "# 10.4 스파크 SQL 쿼리 실행 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6024d5fa-a1c3-4e49-933c-84b7264e423c",
   "metadata": {},
   "source": [
    "## 10.4.1 스파크 SQL CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f98577e-6297-4a36-ae51-11529563b6a6",
   "metadata": {},
   "source": [
    "## 10.4.2 스파크의 프로그래밍 SQL 인터페이스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbdcebdf-9b93-468d-a774-f0587a1c10c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.0.2:4040\n",
       "SparkContext available as 'sc' (version = 3.3.2, master = local[*], app id = local-1679646846724)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "res0: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@3aaf14d6\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ebe23f-e19e-4444-ba67-61d66b8731c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|(1 + 1)|\n",
      "+-------+\n",
      "|      2|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT 1+1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2792a71d-07af-4527-a7c9-cfa0766f0701",
   "metadata": {},
   "source": [
    "- 프로그래밍 방식으로 평가할 수 있는 DataFrame을 반환\n",
    "- 다른 트랜스포메이션과 마찬가지로 즉시 실행되지 않고 지연 처리됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fa22cf-a56e-46b6-8c43-3a9e2ea648d3",
   "metadata": {},
   "source": [
    "- SQL과 DataFrame은 완벽하게 연동될 수 있으므로 더 강력함\n",
    "    - 예를 들어 DataFrame을 생성하고 SQL을 사용해 처리할 수 있으며 그 결과를 다시 DataFrame으로 돌려받게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c8f5569-5913-4fc6-b42b-03dac01712d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.json(\"/Users/choyubin/Downloads/Spark-The-Definitive-Guide-master/data/flight-data/json/2015-summary.json\")\n",
    ".createOrReplaceTempView(\"some_sql_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c82b4c9d-1ac3-459a-bd04-5d8843c2968c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: Long = 12\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, sum(count)\n",
    "FROM some_sql_view GROUP BY DEST_COUNTRY_NAME\n",
    "\"\"\")\n",
    ".where(\"DEST_COUNTRY_NAME like 'S%'\").where(\"`sum(count)` > 10\")\n",
    ".count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0dd7af-1e2f-4083-842b-3424af361cfe",
   "metadata": {},
   "source": [
    "## 10.4.3 스파크 SQL 쓰리프트 JDBC/ODBC 서버\n",
    "- 스파크는 자바 데이터베이스 연결(Java Database Connectivity, JDBC) 인터페이스를 제공\n",
    "- 사용자나 원격 프로그램은 스파크 SQL을 실행하기 위해 이 인터페이스로 스파크 드라이버에 접속\n",
    "    - e.g. 비즈니스 분석가가 태블로 같은 비즈니스 인텔리전스 소프트웨어를 이용해 스파크에 접속하는 형태"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0630141-5b08-4df7-bb28-54ab537027f1",
   "metadata": {},
   "source": [
    "# 10.5 카탈로그\n",
    "- 스파크 SQL에서 가장 높은 추상화 단계\n",
    "- 테이블에 저장된 데이터에 대한 메타데이터뿐만 아니라 데이터베이스, 테이블, 함수 그리고 뷰에 대한 정보를 추상화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73661997-d8b1-4bbc-b8b3-84dbddab0182",
   "metadata": {},
   "source": [
    "# 10.6 테이블\n",
    "- 스파크 SQL을 사용해 유용한 작업을 수행하려면 먼저 테이블을 정의해야 함\n",
    "- DataFrame과 논리적으로 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f01936c-4281-4b8a-b40d-4c27e5e991d7",
   "metadata": {},
   "source": [
    "## 10.6.1 스파크 관리형 테이블\n",
    "- 관리형 테이블과 외부 테이블 개념은 반드시 기억\n",
    "- 테이블은 두 가지 중요한 정보를 저장\n",
    "    - 테이블의 데이터\n",
    "    - 테이블에 대한 데이터, 즉 메타데이터\n",
    "- 스파크는 데이터뿐만 아니라 파일에 대한 메타데이터를 관리할 수 있음\n",
    "- 디스크에 저장된 파일을 이용해 테이블을 정의하면 외부 테이블을 정의하는 것\n",
    "- DataFrame의 saveAsTable 메서드는 스파크가 관련된 모든 정보를 추적할 수 있는 관리형 테이블을 만들 수 있음\n",
    "    - saveAsTable 메서드는 테이블을 읽고 데이터를 스파크 포맷으로 변환한 후 새로운 경로에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c51ac8c-cc3e-49a3-96b6-718ac584e84b",
   "metadata": {},
   "source": [
    "## 10.6.2 테이블 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7614c437-7904-4b9a-a605-36afc1b19678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE TABLE flights_csv(DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING COMMENT \"remember, the US will be most prevalent\", count LONG)\n",
    "USING csv OPTIONS (header true, path '/Users/choyubin/Downloads/Spark-The-Definitive-Guide-master/data/flight-data/csv/2015-summary.csv')\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6bbce47-2ce3-4271-b25d-da11893822a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE TABLE flights (\n",
    "DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count LONG)\n",
    "USING JSON OPTIONS (path '/Users/choyubin/Downloads/Spark-The-Definitive-Guide-master/data/flight-data/json/2015-summary.json')\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4d64fc1-bb9c-45ae-8302-d76b61309282",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "org.apache.spark.sql.AnalysisException",
     "evalue": " Can not create the managed table('`default`.`flights_from_select`'). The associated location('file:/Users/choyubin/Documents/spark/spark-3.3.2-bin-hadoop3/spark-warehouse/flights_from_select') already exists.",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.sql.AnalysisException: Can not create the managed table('`default`.`flights_from_select`'). The associated location('file:/Users/choyubin/Documents/spark/spark-3.3.2-bin-hadoop3/spark-warehouse/flights_from_select') already exists.",
      "  at org.apache.spark.sql.errors.QueryCompilationErrors$.cannotOperateManagedTableWithExistingLocationError(QueryCompilationErrors.scala:597)",
      "  at org.apache.spark.sql.catalyst.catalog.SessionCatalog.validateTableLocation(SessionCatalog.scala:386)",
      "  at org.apache.spark.sql.execution.command.CreateDataSourceTableAsSelectCommand.run(createDataSourceTables.scala:175)",
      "  at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)",
      "  at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)",
      "  at org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)",
      "  at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)",
      "  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)",
      "  at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)",
      "  at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)",
      "  at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)",
      "  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)",
      "  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)",
      "  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)",
      "  at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)",
      "  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)",
      "  at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)",
      "  at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:560)",
      "  at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)",
      "  at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)",
      "  at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)",
      "  at org.apache.spark.sql.Dataset.<init>(Dataset.scala:220)",
      "  at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:100)",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)",
      "  at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)",
      "  at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:622)",
      "  at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)",
      "  at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:617)",
      "  ... 34 elided",
      ""
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE TABLE flights_from_select USING parquet AS SELECT * FROM flights\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ff38d-3b14-4403-8819-7a80024f994b",
   "metadata": {},
   "source": [
    "## 10.6.4 테이블에 데이터 삽입하기\n",
    "- 데이터 삽입은 표준 SQL 문법을 따름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa9d4257-4cfd-4509-ba7c-05e24daf9193",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res8: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"INSERT INTO flights_from_select\n",
    "SELECT DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME, count FROM flights LIMIT 20\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c74b92e-51e0-40bc-b0b2-86dfa372d2bd",
   "metadata": {},
   "source": [
    "## 10.6.5 테이블 메타데이터 확인하기\n",
    "- 테이블 생성 시 코멘트를 추가할 수 있음. 추가된 코멘트를 확인하려면 DESCRIBE 구문을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1baedf32-ebdf-4f4c-b052-11745b7ff76d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------------------+\n",
      "|           col_name|data_type|             comment|\n",
      "+-------------------+---------+--------------------+\n",
      "|  DEST_COUNTRY_NAME|   string|                null|\n",
      "|ORIGIN_COUNTRY_NAME|   string|remember, the US ...|\n",
      "|              count|   bigint|                null|\n",
      "+-------------------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"DESCRIBE TABLE flights_csv\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6d1c6a-7602-4042-938b-ecb6adade032",
   "metadata": {},
   "source": [
    "## 10.6.6 테이블 메타데이터 갱신하기\n",
    "- REFRESH TABLE\n",
    "    - 테이블과 관련된 모든 캐싱된 항목을 갱신\n",
    "- REPAIR TABLE\n",
    "    - 새로운 파티션 정보를 수집하는 데 초점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ac8b495-bd6d-4e5d-987b-1aa159d5340b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "REFRESH flight_csv\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4850e574-25f9-428f-82ce-014d358aea5e",
   "metadata": {},
   "source": [
    "## 10.6.7 테이블 제거하기\n",
    "- delete(삭제) 불가\n",
    "- drop(제거)만 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8076360f-4b79-439a-b6ba-c23e041b176e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res10: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "DROP TABLE flights_csv\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bea2264e-df7b-4464-bd2b-3fc84e8b4906",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res11: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "DROP TABLE IF EXISTS flights_csv\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7443897a-7f31-4844-a6c6-33c0813dc950",
   "metadata": {},
   "source": [
    "# 10.7 뷰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eaa8a9-698a-4fef-8ff8-e68de8da20e1",
   "metadata": {},
   "source": [
    "## 10.7.1 뷰 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "573e1bed-f82d-4c08-bfc2-f3b56823d0a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sql1: String =\n",
       "\"\n",
       "CREATE VIEW just_usa_view AS\n",
       "SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
       "\"\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sql1 = \"\"\"\n",
    "CREATE VIEW just_usa_view AS\n",
    "SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36f72f8a-43da-4fab-9835-f793d54c5431",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res12: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(sql1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "206ccefa-1d52-49d4-b8ba-4f6dc01328ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sql2: String =\n",
       "\"\n",
       "CREATE TEMP VIEW just_usa_view_temp AS\n",
       "SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
       "\"\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sql2 = \"\"\"\n",
    "CREATE TEMP VIEW just_usa_view_temp AS\n",
    "SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa568c08-6615-4092-af40-9f35f2d955a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res13: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(sql2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc4478bd-add9-460e-b357-a101002fc9df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sql3: String =\n",
       "\"\n",
       "CREATE GLOBAL TEMP VIEW just_usa_global_view_temp AS\n",
       "SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
       "\"\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sql3 = \"\"\"\n",
    "CREATE GLOBAL TEMP VIEW just_usa_global_view_temp AS\n",
    "SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7247a28-a835-4634-9009-8e930f4f385e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res14: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(sql3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fcbaca8-c6cc-4eed-b27e-7bea66106979",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res15: org.apache.spark.sql.DataFrame = [namespace: string, tableName: string ... 1 more field]\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SHOW TABLES\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e18d113b-7b39-44e9-8deb-16a993532786",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sql4: String =\n",
       "\"\n",
       "CREATE OR REPLACE TEMP VIEW just_usa_view_temp AS\n",
       "SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
       "\"\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sql4 = \"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW just_usa_view_temp AS\n",
    "SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99d4bb22-135a-4b17-ac3e-2ffe842b9426",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res16: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(sql4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff8b0b62-d892-4a95-96a5-b04f9ed09aa5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res17: org.apache.spark.sql.DataFrame = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM just_usa_view_temp\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f88096-465f-4226-b2b6-44762a9c271d",
   "metadata": {},
   "source": [
    "## 10.7.2 뷰 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26bc5a22-8d33-49c4-985b-3097acee1372",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sql5: String =\n",
       "\"\n",
       "DROP VIEW IF EXISTS just_usa_view;\n",
       "\"\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sql5 = \"\"\"\n",
    "DROP VIEW IF EXISTS just_usa_view;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d4d6162-369e-406c-9c9d-f4d0f12180f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res18: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(sql5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc75a76-e415-4748-8bf2-a6d5676bc66a",
   "metadata": {},
   "source": [
    "# 10.8 데이터베이스\n",
    "- 데이터베이스를 정의하지 않으면 스파크는 기본 데이터베이스를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcdfea3c-4f75-439a-ac40-8abcb7fd27ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "show databases\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7532bfba-ff90-4ae4-8a25-ab220876511d",
   "metadata": {},
   "source": [
    "## 10.8.1 데이터베이스 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79b03a29-1011-40b9-936f-4510c8dae575",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res21: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "create database some_db\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf20700-8f4c-4ab3-a9fe-a8e2ec10e177",
   "metadata": {},
   "source": [
    "## 10.8.2 데이터베이스 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3eb34beb-e136-48e4-bda9-d44b75bd593c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res22: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "use some_db\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3aa1f0fb-69e8-4b85-a644-9de30ebc3995",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+-----------+\n",
      "|namespace|         tableName|isTemporary|\n",
      "+---------+------------------+-----------+\n",
      "|         |just_usa_view_temp|       true|\n",
      "|         |     some_sql_view|       true|\n",
      "+---------+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SHOW tables\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edc6bf45-656f-45c9-b026-6a0feec7a7b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM default.flights\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98d34553-15cc-4595-b01d-d7c16349cca4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|current_database()|\n",
      "+------------------+\n",
      "|           some_db|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select current_database()\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0a6dc7-6f16-4473-b52b-a6223d854509",
   "metadata": {},
   "source": [
    "## 10.8.3 데이터베이스 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6818dd57-4a01-4e36-9c09-001df56c5418",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res26: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "drop database if exists some_db;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f465cff9-943a-406b-9932-067c0f167f17",
   "metadata": {},
   "source": [
    "# 10.10 고급 주제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f7c59c-02e5-48d5-8cb3-0d06c17cc015",
   "metadata": {},
   "source": [
    "## 10.10.1 복합 데이터 타입\n",
    "- 표준 SQL에는 존재하지 않는 매우 강력한 기능\n",
    "- 구조체, 리스트, 맵"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e7f6ac-d0cd-44a5-99b8-17c1ec412f9c",
   "metadata": {},
   "source": [
    "### 구조체\n",
    "- 스파크에서 중첩 데이터를 생성하거나 쿼리하는 방법을 제공\n",
    "- 구조체를 만들기 위해서는 여러 컬럼이나 표현식을 괄호로 묶기만 하면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "132f8de1-7349-4cf6-af24-b1e45dd04fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res27: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "use default\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a4dd9c9-a54e-438f-90af-87165d31f477",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "create view if not exists nested_data as\n",
    "select (dest_country_name, origin_country_name) as country, count from flights\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39aa93cc-5f50-4296-a056-a36c9369b05b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|dest_country_name|origin_country_name|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|             null|               null|   15|\n",
      "|             null|               null|    1|\n",
      "|             null|               null|  344|\n",
      "|             null|               null|   15|\n",
      "|             null|               null|   62|\n",
      "|             null|               null|    1|\n",
      "|             null|               null|   62|\n",
      "|             null|               null|  588|\n",
      "|             null|               null|   40|\n",
      "|             null|               null|    1|\n",
      "|             null|               null|  325|\n",
      "|             null|               null|   39|\n",
      "|             null|               null|   64|\n",
      "|             null|               null|    1|\n",
      "|             null|               null|   41|\n",
      "|             null|               null|   30|\n",
      "|             null|               null|    6|\n",
      "|             null|               null|    4|\n",
      "|             null|               null|  230|\n",
      "|             null|               null|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select country.*, count from nested_data\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab25666b-ed8a-4fa0-b00e-b73482e9525a",
   "metadata": {},
   "source": [
    "### 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d37f0d7e-a279-436d-bd69-0f29d294f1bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+---------------+\n",
      "|            new_name|flight_counts|     origin_set|\n",
      "+--------------------+-------------+---------------+\n",
      "|             Algeria|          [4]|[United States]|\n",
      "|              Angola|         [15]|[United States]|\n",
      "|            Anguilla|         [41]|[United States]|\n",
      "| Antigua and Barbuda|        [126]|[United States]|\n",
      "|           Argentina|        [180]|[United States]|\n",
      "|               Aruba|        [346]|[United States]|\n",
      "|           Australia|        [329]|[United States]|\n",
      "|             Austria|         [62]|[United States]|\n",
      "|          Azerbaijan|         [21]|[United States]|\n",
      "|             Bahrain|         [19]|[United States]|\n",
      "|            Barbados|        [154]|[United States]|\n",
      "|             Belgium|        [259]|[United States]|\n",
      "|              Belize|        [188]|[United States]|\n",
      "|             Bermuda|        [183]|[United States]|\n",
      "|             Bolivia|         [30]|[United States]|\n",
      "|Bonaire, Sint Eus...|         [58]|[United States]|\n",
      "|              Brazil|        [853]|[United States]|\n",
      "|British Virgin Is...|        [107]|[United States]|\n",
      "|            Bulgaria|          [3]|[United States]|\n",
      "|        Burkina Faso|          [1]|[United States]|\n",
      "+--------------------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select dest_country_name as new_name, collect_list(count) as flight_counts,\n",
    "collect_set(origin_country_name) as origin_set\n",
    "from flights group by dest_country_name\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f660326-48f7-4e46-a951-8bb25c33a137",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|   dest_country_name|array(1, 2, 3)|\n",
      "+--------------------+--------------+\n",
      "|       United States|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|               Egypt|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|          Costa Rica|     [1, 2, 3]|\n",
      "|             Senegal|     [1, 2, 3]|\n",
      "|             Moldova|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|              Guyana|     [1, 2, 3]|\n",
      "|               Malta|     [1, 2, 3]|\n",
      "|            Anguilla|     [1, 2, 3]|\n",
      "|             Bolivia|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "|             Algeria|     [1, 2, 3]|\n",
      "|Turks and Caicos ...|     [1, 2, 3]|\n",
      "|       United States|     [1, 2, 3]|\n",
      "+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select dest_country_name, array(1, 2, 3) from flights\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "010ad884-dc51-4860-8e44-f91186af4687",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+\n",
      "|            new_name|collect_list(count)[0]|\n",
      "+--------------------+----------------------+\n",
      "|             Algeria|                     4|\n",
      "|              Angola|                    15|\n",
      "|            Anguilla|                    41|\n",
      "| Antigua and Barbuda|                   126|\n",
      "|           Argentina|                   180|\n",
      "|               Aruba|                   346|\n",
      "|           Australia|                   329|\n",
      "|             Austria|                    62|\n",
      "|          Azerbaijan|                    21|\n",
      "|             Bahrain|                    19|\n",
      "|            Barbados|                   154|\n",
      "|             Belgium|                   259|\n",
      "|              Belize|                   188|\n",
      "|             Bermuda|                   183|\n",
      "|             Bolivia|                    30|\n",
      "|Bonaire, Sint Eus...|                    58|\n",
      "|              Brazil|                   853|\n",
      "|British Virgin Is...|                   107|\n",
      "|            Bulgaria|                     3|\n",
      "|        Burkina Faso|                     1|\n",
      "+--------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select dest_country_name as new_name, collect_list(count)[0]\n",
    "from flights group by dest_country_name\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3c215b7-12bc-44ae-b381-0df67555b003",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "create or replace temp view flights_agg as\n",
    "select dest_country_name, collect_list(count) as collected_counts\n",
    "from flights group by dest_country_name\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "774fec6f-6503-4fc7-b19f-08e2506fa253",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|col|   dest_country_name|\n",
      "+---+--------------------+\n",
      "|  4|             Algeria|\n",
      "| 15|              Angola|\n",
      "| 41|            Anguilla|\n",
      "|126| Antigua and Barbuda|\n",
      "|180|           Argentina|\n",
      "|346|               Aruba|\n",
      "|329|           Australia|\n",
      "| 62|             Austria|\n",
      "| 21|          Azerbaijan|\n",
      "| 19|             Bahrain|\n",
      "|154|            Barbados|\n",
      "|259|             Belgium|\n",
      "|188|              Belize|\n",
      "|183|             Bermuda|\n",
      "| 30|             Bolivia|\n",
      "| 58|Bonaire, Sint Eus...|\n",
      "|853|              Brazil|\n",
      "|107|British Virgin Is...|\n",
      "|  3|            Bulgaria|\n",
      "|  1|        Burkina Faso|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select explode(collected_counts), dest_country_name from flights_agg\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109216dd-3ab9-4b53-a911-739f82bcef77",
   "metadata": {},
   "source": [
    "## 10.10.2 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf40c34c-4448-4a72-80cb-fbc450340f24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|function|\n",
      "+--------+\n",
      "|       !|\n",
      "|      !=|\n",
      "|       %|\n",
      "|       &|\n",
      "|       *|\n",
      "|       +|\n",
      "|       -|\n",
      "|       /|\n",
      "|       <|\n",
      "|      <=|\n",
      "|     <=>|\n",
      "|      <>|\n",
      "|       =|\n",
      "|      ==|\n",
      "|       >|\n",
      "|      >=|\n",
      "|       ^|\n",
      "|     abs|\n",
      "|    acos|\n",
      "|   acosh|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "show functions\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fbe28a-6e62-4001-a098-cdc1e5a000f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "spark.sql(\"\"\"\n",
    "show system functions\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32bfba60-a5b0-47e7-89dd-70e77fe6dc66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|function|\n",
      "+--------+\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "show user functions\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf801e24-6139-4c58-a731-ecf2d0c5d04a",
   "metadata": {},
   "source": [
    "### 사용자 정의 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "28418d9b-0037-4369-af09-64de1cc98f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "power3: (number: Double)Double\n",
       "res44: org.apache.spark.sql.expressions.UserDefinedFunction = SparkUserDefinedFunction($Lambda$5099/0x0000000802270620@4440c7a6,DoubleType,List(Some(class[value[0]: double])),Some(class[value[0]: double]),Some(power3),false,true)\n"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def power3(number:Double):Double = number * number * number\n",
    "spark.udf.register(\"power3\", power3(_:Double):Double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88706799-931a-453a-99b4-ac71ba75ee27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+\n",
      "|count|power3(count)|\n",
      "+-----+-------------+\n",
      "|   15|       3375.0|\n",
      "|    1|          1.0|\n",
      "|  344|  4.0707584E7|\n",
      "|   15|       3375.0|\n",
      "|   62|     238328.0|\n",
      "|    1|          1.0|\n",
      "|   62|     238328.0|\n",
      "|  588| 2.03297472E8|\n",
      "|   40|      64000.0|\n",
      "|    1|          1.0|\n",
      "|  325|  3.4328125E7|\n",
      "|   39|      59319.0|\n",
      "|   64|     262144.0|\n",
      "|    1|          1.0|\n",
      "|   41|      68921.0|\n",
      "|   30|      27000.0|\n",
      "|    6|        216.0|\n",
      "|    4|         64.0|\n",
      "|  230|     1.2167E7|\n",
      "|    1|          1.0|\n",
      "+-----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select count, power3(count) from flights\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a850e787-20d5-4b21-b6b6-828658a3e0f2",
   "metadata": {},
   "source": [
    "### 서브쿼리\n",
    "- 쿼리 안에 쿼리를 지정\n",
    "- 상호연관 서브쿼리\n",
    "    - 서브쿼리의 정보를 보완하기 위해 쿼리의 외부 범위에 있는 일부 정보를 사용할 수 있음\n",
    "- 비상호연관 서브쿼리\n",
    "    - 외부 범위에 있는 정보를 사용하지 않음\n",
    "- 조건절 서브쿼리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eb8783-a5a4-4629-bd6f-0deaf7426e5e",
   "metadata": {},
   "source": [
    "### 비상호연관 조건절 서브쿼리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a57010d0-c1b9-430a-94ae-a3a6229bd851",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sql11: String =\n",
       "\"\n",
       "select dest_country_name from flights\n",
       "GROUP BY dest_country_name ORDER BY sum(count) DESC LIMIT 5\n",
       "\"\n"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sql11 = \"\"\"\n",
    "select dest_country_name from flights\n",
    "GROUP BY dest_country_name ORDER BY sum(count) DESC LIMIT 5\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0680bf5f-c9fe-4002-a38c-f9933e4f17d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|dest_country_name|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|           Canada|\n",
      "|           Mexico|\n",
      "|   United Kingdom|\n",
      "|            Japan|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(sql11).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c074429e-451b-497e-8528-1306898516da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sql12: String =\n",
       "\"\n",
       "select * from flights\n",
       "where origin_country_name in (select dest_country_name from flights\n",
       "GROUP BY dest_country_name ORDER BY sum(count) DESC LIMIT 5)\n",
       "\"\n"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sql12 = \"\"\"\n",
    "select * from flights\n",
    "where origin_country_name in (select dest_country_name from flights\n",
    "GROUP BY dest_country_name ORDER BY sum(count) DESC LIMIT 5)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "60dbf0f8-d698-42f9-8fc4-bf6efb7bee22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|               Egypt|      United States|   15|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|               Italy|      United States|  382|\n",
      "|            Pakistan|      United States|   12|\n",
      "|             Iceland|      United States|  181|\n",
      "|    Marshall Islands|      United States|   42|\n",
      "|          Luxembourg|      United States|  155|\n",
      "|            Honduras|      United States|  362|\n",
      "|         The Bahamas|      United States|  955|\n",
      "|         El Salvador|      United States|  561|\n",
      "|               Samoa|      United States|   25|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(sql12).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e49ad7-c8ff-4203-8f32-7437b2b18922",
   "metadata": {},
   "source": [
    "### 상호연관 조건절 서브쿼리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2765a13-1b5f-42e6-9564-560f8f04be98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sql13: String =\n",
       "\"\n",
       "select * from flights f1\n",
       "where exists (select 1 from flights f2\n",
       "where f1.dest_country_name = f2.origin_country_name)\n",
       "and exists (select 1 from flights f2\n",
       "where f2.dest_country_name = f1.origin_country_name)\n",
       "\"\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sql13 = \"\"\"\n",
    "select * from flights f1\n",
    "where exists (select 1 from flights f2\n",
    "where f1.dest_country_name = f2.origin_country_name)\n",
    "and exists (select 1 from flights f2\n",
    "where f2.dest_country_name = f1.origin_country_name)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b5d75e1-2e66-4b03-b8df-1006f414534b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|   DEST_COUNTRY_NAME| ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+--------------------+-----+\n",
      "|       United States|             Romania|   15|\n",
      "|       United States|             Croatia|    1|\n",
      "|       United States|             Ireland|  344|\n",
      "|               Egypt|       United States|   15|\n",
      "|       United States|               India|   62|\n",
      "|       United States|           Singapore|    1|\n",
      "|       United States|             Grenada|   62|\n",
      "|          Costa Rica|       United States|  588|\n",
      "|             Senegal|       United States|   40|\n",
      "|       United States|        Sint Maarten|  325|\n",
      "|       United States|    Marshall Islands|   39|\n",
      "|              Guyana|       United States|   64|\n",
      "|               Malta|       United States|    1|\n",
      "|            Anguilla|       United States|   41|\n",
      "|             Bolivia|       United States|   30|\n",
      "|       United States|            Paraguay|    6|\n",
      "|Turks and Caicos ...|       United States|  230|\n",
      "|               Italy|       United States|  382|\n",
      "|       United States|Federated States ...|   69|\n",
      "|       United States|              Russia|  161|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(sql13).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55762f3-af06-4b1c-a5e7-61b6e7054101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
